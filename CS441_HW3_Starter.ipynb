{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gd7scc-8QJvE"
      },
      "source": [
        "## CS441: Applied ML - HW 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagOldZDQJvG"
      },
      "source": [
        "## Part 1: Spam Detection with Naive Bayes Classifier\n",
        "\n",
        "We want to classify text messages as “spam” (unwanted) or “ham” (genuine). We will use data (spam.csv) from the Kaggle SMS spam dataset. We’ve provided the loading and pre-processing code to generate:\n",
        "* `unique_words`: the unique set of words in the dataset\n",
        "* `(x_train, y_train, msg_train)`: counts of words in each message, spam (y=1) or not spam (y=-1) labels, and the message string for each training sample; `x_train[n][j]` is the count of the `j`th word in the `n`th sample.\n",
        "* `*_val` and `*_test`, similar to above, for the val and test splits\n",
        "We will use a Naive Bayes Classifier.\n",
        "\n",
        "See assignment for details (equations are not easy to reproduce here)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "datadir = \"/content/drive/My Drive/CS441/hw3/\" # choose proper location\n",
        "\n",
        "# don't change the code below\n",
        "\n",
        "# read data\n",
        "with open(datadir + 'spam.csv', encoding='latin-1') as csvfile:\n",
        "    datareader = csv.reader(csvfile, delimiter=',')\n",
        "    y = np.zeros((10000,))\n",
        "    X = []\n",
        "    n = 0\n",
        "    rownum = 0\n",
        "    for row in datareader:\n",
        "      if rownum == 0:\n",
        "        rownum += 1\n",
        "        continue\n",
        "      rownum += 1\n",
        "      if row[0]=='ham':\n",
        "        y[n] = -1\n",
        "      else:\n",
        "        y[n] = 1\n",
        "      X.append(row[1])\n",
        "      n += 1\n",
        "y= y[:n]\n",
        "\n",
        "# y[n] = -1 for ham, 1 for spam\n",
        "print(y[0])\n",
        "print(X[0])\n",
        "\n",
        "# parse the text messages into words and count the words in each row\n",
        "vectorizer = CountVectorizer(analyzer='word')\n",
        "word_count = vectorizer.fit_transform(X).toarray()\n",
        "\n",
        "print(f\"We have {word_count.shape[0]} examples with {word_count.shape[1]} unique words.\")\n",
        "unique_words = vectorizer.get_feature_names_out()\n",
        "\n",
        "# split data into train (50%), validation (25%), and test (25%)\n",
        "x_train = word_count[::2]\n",
        "y_train = y[::2]\n",
        "msg_train = X[::2]\n",
        "x_val = word_count[1::4]\n",
        "y_val = y[1::4]\n",
        "msg_val = X[1::4]\n",
        "x_test = word_count[3::4]\n",
        "y_test = y[3::4]\n",
        "msg_test = X[3::4]\n"
      ],
      "metadata": {
        "id": "EBzNRkN2AmWA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d2c3a83-4219-47a6-f2c6-f43dd789c400"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "-1.0\n",
            "Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...\n",
            "We have 5572 examples with 8672 unique words.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Train your Naive Bayes Classifier\n",
        "I.e. P(y), P(w|y)) using the train set with =1 and compute the accuracy on the val set.  You should get P(y=1)=0.142, P(call|spam) = 0.0104, and P(call|ham)=0.0029. Your validation accuracy should be higher than 95%."
      ],
      "metadata": {
        "id": "pTZ05VOmAshI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 1.0\n",
        "V = x_train.shape[1]\n",
        "\n",
        "\n",
        "n_spam = (y_train == 1).sum()\n",
        "n_ham  = (y_train == -1).sum()\n",
        "prior = np.array([n_ham, n_spam], dtype=float) / y_train.size\n",
        "log_prior = np.log(prior + 1e-9)\n",
        "\n",
        "\n",
        "X_spam = x_train[y_train == 1].sum(axis=0).astype(float)\n",
        "X_ham  = x_train[y_train == -1].sum(axis=0).astype(float)\n",
        "pw_spam = (X_spam + alpha) / (X_spam.sum() + alpha * V)\n",
        "pw_ham  = (X_ham  + alpha) / (X_ham.sum()  + alpha * V)\n",
        "\n",
        "\n",
        "log_pw = np.vstack([np.log(pw_ham), np.log(pw_spam)])\n",
        "\n",
        "\n",
        "try:\n",
        "    call_idx = np.where(unique_words == \"call\")[0][0]\n",
        "    print(f\"P(y=1)={prior[1]:.3f}, P(call|spam)={pw_spam[call_idx]:.4f}, P(call|ham)={pw_ham[call_idx]:.4f}\")\n",
        "except IndexError:\n",
        "    print(f'P(y=1)={prior[1]:.3f}  (token \"call\" not in vocabulary)')\n",
        "\n",
        "\n",
        "ll_val = x_val @ log_pw.T + log_prior\n",
        "\n",
        "y_pred_val = ll_val.argmax(axis=1)\n",
        "val_acc = (y_pred_val == (y_val + 1) // 2).mean()\n",
        "print(f\"Validation accuracy = {val_acc:.4f}\")"
      ],
      "metadata": {
        "id": "nVa3s_iYAwkv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa71c98b-5d0d-4ced-c276-5554258e1ee4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(y=1)=0.142, P(call|spam)=0.0104, P(call|ham)=0.0029\n",
            "Validation accuracy = 0.9813\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Data exploration\n",
        "What are the 10 spammiest words (i.e. words with highest  logP(wj|spam)- logP(wj|ham))?  What are the 10 hammiest words? Which val message is the spammiest ham (message with highest spam score but y=-1)? Which is hammiest spam (message with lowest spam score but y=1)?  Spammiest spam? Hammiest ham?"
      ],
      "metadata": {
        "id": "me2ooMJ8A1qw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "log_odds = log_pw[1] - log_pw[0]\n",
        "\n",
        "sidx = np.argsort(log_odds)[-10:]\n",
        "print(\"10 spammiest words:\")\n",
        "print(\"\\n\".join([unique_words[i] for i in sidx]))\n",
        "\n",
        "\n",
        "hidx = np.argsort(log_odds)[:10]\n",
        "print(\"\\n10 hammiest words:\")\n",
        "print(\"\\n\".join([unique_words[i] for i in hidx]))\n",
        "\n",
        "\n",
        "def choose_data():\n",
        "    sets = [\n",
        "        (x_val, y_val, msg_val),\n",
        "        (x_test, y_test, msg_test),\n",
        "        (x_train, y_train, msg_train),\n",
        "        (np.vstack([x_val, x_test]),\n",
        "         np.concatenate([y_val, y_test]),\n",
        "         np.array(list(msg_val)+list(msg_test), dtype=object)),\n",
        "        (np.vstack([x_train, x_val, x_test]),\n",
        "         np.concatenate([y_train, y_val, y_test]),\n",
        "         np.array(list(msg_train)+list(msg_val)+list(msg_test), dtype=object))\n",
        "    ]\n",
        "    for X,Y,M in sets:\n",
        "\n",
        "        if (-1 in Y) and (1 in Y):\n",
        "            return X,Y,M\n",
        "    return sets[-1]\n",
        "\n",
        "X,Y,M = choose_data()\n",
        "ll = X @ log_pw.T + log_prior\n",
        "p = 1/(1+np.exp(-np.clip(ll[:,1]-ll[:,0], -50, 50)))\n",
        "\n",
        "ham, spam = (Y==-1), (Y==1)\n",
        "\n",
        "\n",
        "i_sh = np.where(ham)[0][np.argmax(p[ham])] if np.any(ham) else None\n",
        "i_hs = np.where(spam)[0][np.argmin(p[spam])] if np.any(spam) else None\n",
        "i_ss = np.where(spam)[0][np.argmax(p[spam])] if np.any(spam) else None\n",
        "i_hh = np.where(ham)[0][np.argmin(p[ham])] if np.any(ham) else None\n",
        "\n",
        "\n",
        "if i_sh is not None:\n",
        "    print(\"\\nSpammiest ham\\n\"+M[i_sh]+\"\\nscore=\"+str(float(p[i_sh])))\n",
        "else:\n",
        "    print(\"\\nSpammiest ham: Not found\")\n",
        "\n",
        "if i_hs is not None:\n",
        "    print(\"\\nHammiest spam\\n\"+M[i_hs]+\"\\nscore=\"+str(float(p[i_hs])))\n",
        "else:\n",
        "    print(\"\\nHammiest spam: Not found\")\n",
        "\n",
        "if i_ss is not None:\n",
        "    print(\"\\nSpammiest spam\\n\"+M[i_ss]+\"\\nscore=\"+str(float(p[i_ss])))\n",
        "else:\n",
        "    print(\"\\nSpammiest spam: Not found\")\n",
        "\n",
        "if i_hh is not None:\n",
        "    print(\"\\nHammiest ham\\n\"+M[i_hh]+\"\\nscore=\"+str(float(p[i_hh])))\n",
        "else:\n",
        "    print(\"\\nHammiest ham: Not found\")"
      ],
      "metadata": {
        "id": "i2b_U4qbIa1D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57f891fb-be81-4b57-e16d-4859237478ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 spammiest words:\n",
            "18\n",
            "cs\n",
            "16\n",
            "500\n",
            "tone\n",
            "www\n",
            "150p\n",
            "uk\n",
            "prize\n",
            "claim\n",
            "\n",
            "10 hammiest words:\n",
            "gt\n",
            "lt\n",
            "he\n",
            "but\n",
            "lor\n",
            "da\n",
            "she\n",
            "later\n",
            "ì_\n",
            "wat\n",
            "\n",
            "Spammiest ham\n",
            "Waqt se pehle or naseeb se zyada kisi ko kuch nahi milta,Zindgi wo nahi he jo hum sochte hai Zindgi wo hai jo ham jeetey hai..........\n",
            "score=0.9999875249999429\n",
            "\n",
            "Hammiest spam\n",
            "LIFE has never been this much fun and great until you came in. You made it truly special for me. I won't forget you! enjoy @ one gbp/sms\n",
            "score=9.411404471768725e-10\n",
            "\n",
            "Spammiest spam\n",
            "Please call our customer service representative on 0800 169 6031 between 10am-9pm as you have WON a guaranteed å£1000 cash or å£5000 prize!\n",
            "score=1.0\n",
            "\n",
            "Hammiest ham\n",
            "Wow. I never realized that you were so embarassed by your accomodations. I thought you liked it, since i was doing the best i could and you always seemed so happy about \\the cave\\\". I'm sorry I didn't and don't have more to give. I'm sorry i offered. I'm sorry your room was so embarassing.\"\n",
            "score=1.928749847963918e-22\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Precision-recall trade-off\n",
        "You want to flag spam messages with minimal false positives. Using the val set, compute precision/recall and display the PR curve. Programmatically, find the threshold with highest recall, where precision > 0.99.  Report the accuracy, precision, and recall on the test set using the same model and the selected threshold."
      ],
      "metadata": {
        "id": "B04qPuOaBIlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "\n",
        "# TO DO\n",
        "\n",
        "\n",
        "ll = x_val @ log_pw.T + log_prior\n",
        "p_val = 1/(1+np.exp(-np.clip(ll[:,1]-ll[:,0], -50, 50)))\n",
        "prec, rec, thr = precision_recall_curve(y_val, p_val)\n",
        "m = np.where(prec[1:] > 0.99)[0]\n",
        "j = m[np.argmax(rec[1:][m])] if m.size else np.argmax(prec[1:])\n",
        "best_thr = float(thr[j])\n",
        "\n",
        "ll_t = x_test @ log_pw.T + log_prior\n",
        "p_test = 1/(1+np.exp(-np.clip(ll_t[:,1]-ll_t[:,0], -50, 50)))\n",
        "y_pred = (p_test >= best_thr).astype(int)\n",
        "tp = int(((y_test==1)&(y_pred==1)).sum())\n",
        "tn = int(((y_test==0)&(y_pred==0)).sum())\n",
        "fp = int(((y_test==0)&(y_pred==1)).sum())\n",
        "fn = int(((y_test==1)&(y_pred==0)).sum())\n",
        "acc = (tp+tn)/y_test.size\n",
        "pre = tp/(tp+fp) if tp+fp>0 else 0.0\n",
        "recall = tp/(tp+fn) if tp+fn>0 else 0.0\n",
        "print(f\"threshold={best_thr:.6f}\")\n",
        "print(f\"test_acc={acc:.4f} precision={pre:.4f} recall={recall:.4f}\")\n",
        "\n",
        "plt.plot(rec, prec)\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sjbgB-LHBI9y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "5d4e7a3c-c23e-471a-a186-f175adafb5fb"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "threshold=0.997675\n",
            "test_acc=0.0998 precision=1.0000 recall=0.8081\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Robust Estimation\n",
        "\n",
        "The corrupted salary dataset has three variables: salary, years, school.  Salary is the reported salary of each person.  Years is the number of years of experience in the job.  School is the university where the person last had a degree. For the core assignment, we’ll only use salary, and the stretch goals will use the other two variables. Some of the reported salary information is wrong (some incorrect value is provided), so we want to learn things from the data in a way that is robust to the wrong data. We refer to correctly entered data as “valid”.\n",
        "\n",
        "Estimate the true mean, standard deviation, min, and max of the salaries using three different methods."
      ],
      "metadata": {
        "id": "YK769ZQ4NgUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "datadir = \"/content/drive/My Drive/CS441/hw3/\"\n",
        "\n",
        "# load data\n",
        "T = np.load(datadir + 'salary.npz')\n",
        "(salary, years, school) = (T['salary'], T['years'], T['school'])"
      ],
      "metadata": {
        "id": "Dzb9-YeTnrie",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732c188c-2e22-4875-b790-e6f91965dbe4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Assume no noise\n",
        "Compute the statistics for the data as a whole"
      ],
      "metadata": {
        "id": "zKusZuTmqwIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO\n",
        "salary_mu = np.mean(salary)\n",
        "salary_std = np.std(salary)\n",
        "salary_min = np.min(salary)\n",
        "salary_max = np.max(salary)\n",
        "print('Mean: {}  Std: {}  Min: {}   Max: {}'.format(salary_mu, salary_std, salary_min, salary_max))"
      ],
      "metadata": {
        "id": "U8s5LwbpqaR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c09f6fd-ae07-4128-fb37-f06a2bd6944a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 123749.835  Std: 61953.77348723623  Min: 64694.0   Max: 611494.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Percentiles\n",
        "Assume valid data will fall between the 5th and 95th percentile. Adjust estimates of the min and max by assuming that the valid data has a uniform distribution (see lecture on robust fitting)."
      ],
      "metadata": {
        "id": "8bKArxlbvOvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pct = 0.05\n",
        "\n",
        "# TO DO\n",
        "L = np.percentile(salary, 100*pct)\n",
        "U = np.percentile(salary, 100*(1-pct))\n",
        "mid = salary[(salary>=L)&(salary<=U)]\n",
        "salary_mu = mid.mean()\n",
        "salary_std = mid.std()\n",
        "rng = (U - L)/0.90\n",
        "salary_min = 0.5*(L + U - rng)\n",
        "salary_max = 0.5*(L + U + rng)\n",
        "print('Mean: {}  Std: {}  Min: {}   Max: {}'.format(salary_mu, salary_std, salary_min, salary_max))"
      ],
      "metadata": {
        "id": "OVXCYlx7wGjS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da9430be-941c-4ef5-fec6-0aba79a5ed0d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: 113878.65  Std: 15876.450453939286  Min: 75493.80000000002   Max: 159900.79999999973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. EM\n",
        "Assume valid data follows a Gaussian distribution, while the fake data has a uniform distribution between the minimum and maximum value of salary. For mean and std, report the estimated mean and std of the valid salary distribution. For min and max, report the min and max salaries that have greater than 50% chance of being valid. Also report the estimated probability that a random sample is valid, and the first five indices of salaries that are not likely to be valid."
      ],
      "metadata": {
        "id": "fdQCUF2aq-9p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO\n",
        "\n",
        "\n",
        "a, b = salary.min(), salary.max()\n",
        "mu, sigma, pi = np.median(salary), salary.std(), 0.9\n",
        "U = 1.0/(b - a + 1e-12)\n",
        "for _ in range(100):\n",
        "    N = (1.0/(np.sqrt(2*np.pi)*sigma)) * np.exp(-0.5*((salary - mu)/sigma)**2)\n",
        "    r = (pi*N) / (pi*N + (1 - pi)*U + 1e-12)\n",
        "    mu = (r*salary).sum() / (r.sum() + 1e-12)\n",
        "    sigma = np.sqrt((r*((salary - mu)**2)).sum() / (r.sum() + 1e-12))\n",
        "    pi = r.mean()\n",
        "\n",
        "mask = r > 0.5\n",
        "salary_mu, salary_std = mu, sigma\n",
        "salary_min = salary[mask].min() if mask.any() else a\n",
        "salary_max = salary[mask].max() if mask.any() else b\n",
        "\n",
        "print('P(valid)={:.3f}'.format(pi))\n",
        "\n",
        "print('Mean: {}  Std: {}  Min: {}   Max: {}'.format(salary_mu, salary_std, salary_min, salary_max))\n",
        "\n",
        "# print the first five indices of salaries that are not likely to be valid\n",
        "print(np.where(r<0.5)[0][:5]) # Replaced p_valid_given_s with r"
      ],
      "metadata": {
        "id": "lejhsklSqjbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b5c333-8c6f-4757-afb4-f35db8eeefde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(valid)=0.942\n",
            "Mean: 111984.38414085866  Std: 17966.359253827854  Min: 64694.0   Max: 169008.0\n",
            "[ 18  28  49 127 128]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Stretch Goals\n",
        "Include all your code used for any stretch goals in this section. Add headings where appropriate."
      ],
      "metadata": {
        "id": "3X3j_efPhh6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TO DO (optional)\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "\n",
        "def train_nb(X,y,alpha):\n",
        "    V=X.shape[1]\n",
        "    n1=(y==1).sum(); n0=(y==0).sum()\n",
        "    lp=np.log(np.array([n0,y.size-n0])/y.size+1e-12)\n",
        "    xs=X[y==1].sum(0).astype(float); xh=X[y==0].sum(0).astype(float)\n",
        "    pw1=(xs+alpha)/(xs.sum()+alpha*V); pw0=(xh+alpha)/(xh.sum()+alpha*V)\n",
        "    return lp, np.vstack([np.log(pw0+1e-12), np.log(pw1+1e-12)])\n",
        "\n",
        "def score(lp,lw,X):\n",
        "    ll=X@lw.T+lp\n",
        "    d=np.clip(ll[:,1]-ll[:,0],-50,50)\n",
        "    return 1/(1+np.exp(-d))\n",
        "\n",
        "results=[]\n",
        "best=None\n",
        "for binary in [0,1]:\n",
        "    df_mask=(x_train>0).sum(0)>=1\n",
        "    for df_min in [1,3]:\n",
        "        df_mask=(x_train>0).sum(0)>=df_min\n",
        "        if df_mask.sum()==0:\n",
        "            continue\n",
        "        Xt=x_train[:,df_mask]; Xv=x_val[:,df_mask]; Xte=x_test[:,df_mask]\n",
        "        if binary: Xt=(Xt>0).astype(int); Xv=(Xv>0).astype(int); Xte=(Xte>0).astype(int)\n",
        "        for a in [0.2,0.5,1.0,2.0,4.0]:\n",
        "            lp,lw=train_nb(Xt,y_train,a)\n",
        "            pv=score(lp,lw,Xv)\n",
        "            prec,rec,thr=precision_recall_curve(y_val,pv)\n",
        "            m=np.where(prec[1:]>0.99)[0]\n",
        "            j=m[np.argmax(rec[1:][m])] if m.size else np.argmax(prec[1:])\n",
        "            recall_target=rec[1:][j] if m.size else rec[1:][j]\n",
        "            results.append((recall_target,a,binary,df_min,j,lp,lw,thr,Xte))\n",
        "best=max(results,key=lambda t:t[0])\n",
        "recall_val,a,binary,df_min,j,lp,lw,thr,Xte=best\n",
        "pt=score(lp,lw,Xte); best_thr=float(thr[j])\n",
        "yp=(pt>=best_thr).astype(int)\n",
        "tp=int(((y_test==1)&(yp==1)).sum()); tn=int(((y_test==0)&(yp==0)).sum())\n",
        "fp=int(((y_test==0)&(yp==1)).sum()); fn=int(((y_test==1)&(yp==0)).sum())\n",
        "acc=(tp+tn)/y_test.size; pre=tp/(tp+fp) if tp+fp>0 else 0.0; rec=tp/(tp+fn) if tp+fn>0 else 0.0\n",
        "print(\"best:\", {\"alpha\":a,\"binary\":bool(binary),\"df_min\":df_min,\"thr\":best_thr})\n",
        "print(\"test_acc={:.4f} precision={:.4f} recall={:.4f}\".format(acc,pre,rec))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def em_valid_probs(s):\n",
        "    a,b=s.min(),s.max()\n",
        "    mu=np.median(s); sg=s.std(); pi=0.9; U=1/(b-a+1e-12)\n",
        "    for _ in range(100):\n",
        "        N=(1/(np.sqrt(2*np.pi)*sg))*np.exp(-0.5*((s-mu)/sg)**2)\n",
        "        r=(pi*N)/(pi*N+(1-pi)*U+1e-12)\n",
        "        mu=(r*s).sum()/(r.sum()+1e-12)\n",
        "        sg=np.sqrt((r*((s-mu)**2)).sum()/(r.sum()+1e-12))\n",
        "        pi=r.mean()\n",
        "    return r\n",
        "\n",
        "r = em_valid_probs(salary)\n",
        "m = r>0.5\n",
        "overall = salary[m].mean()\n",
        "uiuc = salary[m & (school==0)].mean() if (m & (school==0)).any() else np.nan\n",
        "mit  = salary[m & (school==1)].mean() if (m & (school==1)).any() else np.nan\n",
        "corn = salary[m & (school==2)].mean() if (m & (school==2)).any() else np.nan\n",
        "print(\"Overall {:.0f}\".format(overall))\n",
        "print(\"School 0 (UIUC) {:.0f}\".format(uiuc))\n",
        "print(\"School 1 (MIT) {:.0f}\".format(mit))\n",
        "print(\"School 2 (Cornell) {:.0f}\".format(corn))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def em_valid_probs(s):\n",
        "    a,b=s.min(),s.max()\n",
        "    mu=np.median(s); sg=s.std(); pi=0.9; U=1/(b-a+1e-12)\n",
        "    for _ in range(100):\n",
        "        N=(1/(np.sqrt(2*np.pi)*sg))*np.exp(-0.5*((s-mu)/sg)**2)\n",
        "        r=(pi*N)/(pi*N+(1-pi)*U+1e-12)\n",
        "        mu=(r*s).sum()/(r.sum()+1e-12)\n",
        "        sg=np.sqrt((r*((s-mu)**2)).sum()/(r.sum()+1e-12))\n",
        "        pi=r.mean()\n",
        "    return r\n",
        "\n",
        "r = em_valid_probs(salary)\n",
        "w = r\n",
        "coef = np.polyfit(years, salary, 1, w=w)\n",
        "slope = coef[0]\n",
        "print(\"Increase per year (slope) {:.2f}\".format(slope))\n",
        "\n"
      ],
      "metadata": {
        "id": "UFZfuCqJqhLc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "565f7cd2-f196-4178-8631-0cdee03453d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best: {'alpha': 0.2, 'binary': False, 'df_min': 1, 'thr': 1.0}\n",
            "test_acc=0.1213 precision=1.0000 recall=0.9826\n",
            "Overall 112066\n",
            "School 0 (UIUC) 119026\n",
            "School 1 (MIT) 105468\n",
            "School 2 (Cornell) 112027\n",
            "Increase per year (slope) 1024.94\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from https://gist.github.com/jonathanagustin/b67b97ef12c53a8dec27b343dca4abba\n",
        "# install can take a minute\n",
        "\n",
        "import os\n",
        "# @title Convert Notebook to PDF. Save Notebook to given directory\n",
        "NOTEBOOKS_DIR = \"/content/drive/MyDrive/CS441/hw3\" # @param {type:\"string\"}\n",
        "NOTEBOOK_NAME = \"CS441_HW3_Solution.ipynb\" # @param {type:\"string\"}\n",
        "#------------------------------------------------------------------------------#\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)\n",
        "NOTEBOOK_PATH = f\"{NOTEBOOKS_DIR}/{NOTEBOOK_NAME}\"\n",
        "assert os.path.exists(NOTEBOOK_PATH), f\"NOTEBOOK NOT FOUND: {NOTEBOOK_PATH}\"\n",
        "!apt install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic > /dev/null 2>&1\n",
        "!jupyter nbconvert \"$NOTEBOOK_PATH\" --to pdf > /dev/null 2>&1\n",
        "NOTEBOOK_PDF = NOTEBOOK_PATH.rsplit('.', 1)[0] + '.pdf'\n",
        "assert os.path.exists(NOTEBOOK_PDF), f\"ERROR MAKING PDF: {NOTEBOOK_PDF}\"\n",
        "print(f\"PDF CREATED: {NOTEBOOK_PDF}\")"
      ],
      "metadata": {
        "id": "5T2IRr7fz6ta",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "outputId": "61997226-fc82-425c-fe02-5810fe09f274"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "NOTEBOOK NOT FOUND: /content/drive/MyDrive/CS441/hw3/CS441_HW3_Solution.ipynb",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2890900681.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mNOTEBOOK_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{NOTEBOOKS_DIR}/{NOTEBOOK_NAME}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNOTEBOOK_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"NOTEBOOK NOT FOUND: {NOTEBOOK_PATH}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'apt install -y texlive-xetex texlive-fonts-recommended texlive-plain-generic > /dev/null 2>&1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jupyter nbconvert \"$NOTEBOOK_PATH\" --to pdf > /dev/null 2>&1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: NOTEBOOK NOT FOUND: /content/drive/MyDrive/CS441/hw3/CS441_HW3_Solution.ipynb"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6HdPSxIFx_uZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}